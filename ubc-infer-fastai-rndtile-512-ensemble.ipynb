{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Infer with Fastai, 512 ensembles\n",
    "\n",
    "* use the trained set on the 512px random tiles with TMA reduced by 2x.\n",
    "* Use 512 models for lr = .01,.025,.036 and then take mode of the three\n",
    "\n",
    "* NOTE: if training was scaled, infer needs to be as well.  Need to keep track of this.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Installs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!ls /kaggle/input/pyvips-python-and-deb-package\n",
    "\n",
    "!dpkg -i --force-depends /kaggle/input/pyvips-python-and-deb-package/linux_packages/archives/*.deb\n",
    "\n",
    "!pip install pyvips -f /kaggle/input/pyvips-python-and-deb-package/python_packages/ --no-index\n",
    "!pip list | grep pyvips"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:54:56.790865Z",
     "iopub.execute_input": "2023-11-12T21:54:56.791319Z",
     "iopub.status.idle": "2023-11-12T21:56:43.729594Z",
     "shell.execute_reply.started": "2023-11-12T21:54:56.791286Z",
     "shell.execute_reply": "2023-11-12T21:56:43.728015Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from statistics import mode\n",
    "\n",
    "import pyvips\n",
    "pyvips.__version__\n",
    "#from PIL import Image"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:26.072518Z",
     "iopub.execute_input": "2023-11-12T21:57:26.072911Z",
     "iopub.status.idle": "2023-11-12T21:57:26.089410Z",
     "shell.execute_reply.started": "2023-11-12T21:57:26.072881Z",
     "shell.execute_reply": "2023-11-12T21:57:26.088151Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "top_dir = '/kaggle/input/UBC-OCEAN'\n",
    "test_dir = '/kaggle/input/UBC-OCEAN/test_images/'\n",
    "test_thumb_dir = '/kaggle/input/UBC-OCEAN/test_thumbnails/'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:32.727182Z",
     "iopub.execute_input": "2023-11-12T21:57:32.727666Z",
     "iopub.status.idle": "2023-11-12T21:57:32.733466Z",
     "shell.execute_reply.started": "2023-11-12T21:57:32.727629Z",
     "shell.execute_reply": "2023-11-12T21:57:32.731939Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ss = pd.read_csv('/kaggle/input/UBC-OCEAN/sample_submission.csv')\n",
    "x_test = pd.read_csv('/kaggle/input/UBC-OCEAN/test.csv')\n",
    "x_test.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:32.977877Z",
     "iopub.execute_input": "2023-11-12T21:57:32.978278Z",
     "iopub.status.idle": "2023-11-12T21:57:32.996867Z",
     "shell.execute_reply.started": "2023-11-12T21:57:32.978248Z",
     "shell.execute_reply": "2023-11-12T21:57:32.995450Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# write_dir = '/kaggle/working/resized_test'\n",
    "# if not os.path.exists(write_dir):\n",
    "#     os.mkdir(write_dir)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:33.750351Z",
     "iopub.execute_input": "2023-11-12T21:57:33.750749Z",
     "iopub.status.idle": "2023-11-12T21:57:33.755556Z",
     "shell.execute_reply.started": "2023-11-12T21:57:33.750719Z",
     "shell.execute_reply": "2023-11-12T21:57:33.754544Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# loop through test folder and make a new resized folder\n",
    "from pathlib import Path\n",
    "\n",
    "# set the training path to use thumbs if available\n",
    "def set_test_path(n):\n",
    "    \n",
    "#     pth = f'{test_thumb_dir}{n}_thumbnail.png'\n",
    "#     if os.path.exists(pth):\n",
    "#         return Path(f'{test_thumb_dir}{n}_thumbnail.png')\n",
    "#     else:\n",
    "\n",
    "    return Path(f'{test_dir}{n}.png')\n",
    "\n",
    "    \n",
    "x_test['test_path'] = x_test.image_id.apply(lambda x: set_test_path(x))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:34.099766Z",
     "iopub.execute_input": "2023-11-12T21:57:34.100231Z",
     "iopub.status.idle": "2023-11-12T21:57:34.109124Z",
     "shell.execute_reply.started": "2023-11-12T21:57:34.100194Z",
     "shell.execute_reply": "2023-11-12T21:57:34.107872Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x_test"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:34.978232Z",
     "iopub.execute_input": "2023-11-12T21:57:34.979490Z",
     "iopub.status.idle": "2023-11-12T21:57:34.990832Z",
     "shell.execute_reply.started": "2023-11-12T21:57:34.979428Z",
     "shell.execute_reply": "2023-11-12T21:57:34.989769Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fastai Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import timm\n",
    "\n",
    "fastai.__version__"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:35.855565Z",
     "iopub.execute_input": "2023-11-12T21:57:35.856783Z",
     "iopub.status.idle": "2023-11-12T21:57:35.865000Z",
     "shell.execute_reply.started": "2023-11-12T21:57:35.856742Z",
     "shell.execute_reply": "2023-11-12T21:57:35.863596Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Swap out model here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# load learner - don't have a trained model on the dataset yet.\n",
    "learn_inf1 = load_learner('/kaggle/input/ubc-ocean-single-tile-models/random_512px_tma_reduced_2x_train.pkl')\n",
    "learn_inf2 = load_learner('/kaggle/input/ubc-ocean-single-tile-models/random_512px_tma_reduced_2x_train_lr_0025.pkl')\n",
    "learn_inf3 = load_learner('/kaggle/input/ubc-ocean-single-tile-models/random_512px_tma_reduced_2x_train_lr_0036.pkl')\n",
    "print('learner loaded')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:37.154703Z",
     "iopub.execute_input": "2023-11-12T21:57:37.155149Z",
     "iopub.status.idle": "2023-11-12T21:57:37.533479Z",
     "shell.execute_reply.started": "2023-11-12T21:57:37.155112Z",
     "shell.execute_reply": "2023-11-12T21:57:37.532098Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictions\n",
    "* First try thumbnails\n",
    "* Removed writing anything and using thumbnails...hopefully will submit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# THIS HAS TO MATCH TRAINING PIPELINE\n",
    "# should be generic so I can use the same function for train and test!\n",
    "\n",
    "def get_random_tile(image, tile_size=512):\n",
    "    \n",
    "    half_tile = int(tile_size/2)\n",
    "    \n",
    "    # get width and height\n",
    "    h, w = image.height, image.width\n",
    "\n",
    "   # halve TMA files (not sure if this is correct)\n",
    "    if image.width in [2964,3388]:\n",
    "        image = image.affine((.5, 0, 0, .5))  \n",
    "        h, w = image.height, image.width\n",
    " \n",
    "    quality = 0.0\n",
    "    thresh = 0.98\n",
    "    count = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # come up with a random crop\n",
    "    while quality < thresh:\n",
    "        \n",
    "        # get two random values\n",
    "        rand_h = np.random.randint(0,h-tile_size)\n",
    "        rand_w = np.random.randint(0,w-tile_size)\n",
    "        #print(f'Random values w,h: {rand_w},{rand_h}')\n",
    "\n",
    "        # get params to crop and produce cropped image\n",
    "        top = rand_h\n",
    "        left = rand_w\n",
    "        \n",
    "        try: \n",
    "            # not sure yet which is better: Image.crop, or region.fetch\n",
    "#           im_out = im_in.crop(top,left,tile_size,tile_size)  # crop original image\n",
    "            region = pyvips.Region.new(image)\n",
    "            im_data = region.fetch(top,left,tile_size,tile_size)\n",
    "            np_data = np.ndarray(buffer=im_data, dtype=np.uint8, shape=[tile_size, tile_size, 3])\n",
    "            im_out = pyvips.Image.new_from_array(np_data)\n",
    "            num_gt_0 = ((im_out > 0).avg() * im_out.width * im_out.height * im_out.bands) / 255\n",
    "            quality = num_gt_0/(3*tile_size**2)  # this is the perecentage of not black pixels\n",
    "            \n",
    "        except:\n",
    "            # try again with new random values, max = 50x\n",
    "  \n",
    "            quality = 0.0\n",
    "            count +=1 \n",
    "            \n",
    "            # if time out, just return an empty image\n",
    "            if count > 50:  \n",
    "                print('Timed out, failed image')\n",
    "                arr = np.zeros((tile_size,tile_size))  # not sure why I have to just use a 2d array here (?)  256x256x3 crashes\n",
    "                im_out = pyvips.Image.new_from_array(arr)\n",
    "                failed +=1\n",
    "                break\n",
    "\n",
    "    return im_out"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:57:38.557275Z",
     "iopub.execute_input": "2023-11-12T21:57:38.557717Z",
     "iopub.status.idle": "2023-11-12T21:57:38.572322Z",
     "shell.execute_reply.started": "2023-11-12T21:57:38.557683Z",
     "shell.execute_reply": "2023-11-12T21:57:38.570837Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loop through test data, process, and predict"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# loop through test and make predictions\n",
    "tile_size = 1024\n",
    "preds = []\n",
    "for idx in range(len(x_test)):\n",
    "    \n",
    "    #load image with pyvips and resize.\n",
    "    img_path = x_test.iloc[idx].test_path\n",
    "    #im = pyvips.Image.thumbnail(img_path, 256)  # don't want to do this, crop to center instead\n",
    "\n",
    "    # load file\n",
    "    im = pyvips.Image.new_from_file(img_path,access='sequential')\n",
    "\n",
    "    # call function to get random tile \n",
    "    im_out = get_random_tile(im,tile_size)\n",
    "\n",
    "    # make predictions\n",
    "    pred1 = learn_inf1.predict(np.asarray(im_out))[0]#x_test.iloc[idx].test_path) \n",
    "    pred2 = learn_inf2.predict(np.asarray(im_out))[0]\n",
    "    pred3 = learn_inf3.predict(np.asarray(im_out))[0]\n",
    "    \n",
    "    best_pred = mode([pred1,pred2,pred3])\n",
    "\n",
    "    preds.append(best_pred)\n",
    "\n",
    "preds"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:58:44.417573Z",
     "iopub.execute_input": "2023-11-12T21:58:44.418302Z",
     "iopub.status.idle": "2023-11-12T21:59:00.341288Z",
     "shell.execute_reply.started": "2023-11-12T21:58:44.418266Z",
     "shell.execute_reply": "2023-11-12T21:59:00.340077Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Submit preds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "ss.label = preds\n",
    "ss.to_csv('submission.csv',index=False)\n",
    "ss.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-12T21:59:05.379269Z",
     "iopub.execute_input": "2023-11-12T21:59:05.379741Z",
     "iopub.status.idle": "2023-11-12T21:59:05.397108Z",
     "shell.execute_reply.started": "2023-11-12T21:59:05.379708Z",
     "shell.execute_reply": "2023-11-12T21:59:05.396067Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
